{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "This notebook is used for training of the network as well as setting of the hyperparameters and visualization of the generator ouputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.nn import BCELoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "# Networks and utility functions\n",
    "from network import Generator, Discriminator, weights_init\n",
    "from utils import get_dataloader_image\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "The `generator_layers` and `discriminator_layers` variables decide the total number of layers and the number of channels in each of them.\n",
    "\n",
    "The `image_size` is set to match given architecture of the generator\n",
    "\n",
    "The `visualization_noise` is set here, so that results across epochs can be directly compared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = \"images\"\n",
    "batch_size = 128\n",
    "latent_size = 200\n",
    "num_epochs = 100\n",
    "learning_rate = 1e-4\n",
    "generator_layers = [latent_size, 512, 256, 128, 64]\n",
    "discriminator_layers = [1, 64, 128, 256, 512]\n",
    "image_size = 2**len(generator_layers)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "beta = 0.5 # Adam hyperparameter\n",
    "\n",
    "visualize = True\n",
    "print_freq = 25\n",
    "visualization_noise = torch.randn(25, latent_size, 1, 1).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train modules\n",
    "Modules setup, no change should be made in this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Discriminator(discriminator_layers).to(device)\n",
    "G = Generator(generator_layers).to(device)\n",
    "D = D.apply(weights_init)\n",
    "G = G.apply(weights_init)\n",
    "\n",
    "loss_fcn = BCELoss()\n",
    "\n",
    "optimizer_D = Adam(D.parameters(), lr=learning_rate, betas=[beta, 0.999])\n",
    "optimizer_G = Adam(G.parameters(), lr=learning_rate, betas=[beta, 0.999])\n",
    "\n",
    "dataloader = get_dataloader_image(image_folder, batch_size, image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "Main train loop. On GTX 1060ti (low-end GPU), this cell ran for ~ 2 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = []\n",
    "for n in range(num_epochs):\n",
    "    for it, images_real in enumerate(dataloader):\n",
    "        # Discriminator update #\n",
    "        D.zero_grad()\n",
    "\n",
    "        images_real = images_real.to(device)\n",
    "        batch_size = images_real.shape[0]\n",
    "        \n",
    "        # Predict real images\n",
    "        label = torch.ones(batch_size, dtype=torch.float).to(device)\n",
    "        predictions_real = D(images_real)\n",
    "\n",
    "        loss_real = loss_fcn(predictions_real, label)\n",
    "        loss_real.backward()\n",
    "\n",
    "        # Generate fake images\n",
    "        input_noise = torch.randn(batch_size, latent_size, 1, 1,).to(device)\n",
    "        images_fake = G(input_noise)\n",
    "\n",
    "        # Predict fake images\n",
    "        label = torch.zeros(batch_size, dtype=torch.float).to(device)\n",
    "        predictions_fake = D(images_fake.detach())\n",
    "\n",
    "        loss_fake = loss_fcn(predictions_fake, label)\n",
    "        loss_fake.backward()\n",
    "\n",
    "        # Update dicriminator weights\n",
    "        loss_discriminator = loss_real + loss_fake\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Generator update #\n",
    "        G.zero_grad()\n",
    "\n",
    "        # Predict fake image\n",
    "        label = torch.ones(batch_size, dtype=torch.float).to(device)\n",
    "        predictions_DG = D(images_fake)\n",
    "        loss_DG = loss_fcn(predictions_DG, label)\n",
    "        \n",
    "        # Update generator weights\n",
    "        loss_DG.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        if visualize and (it + 1) % print_freq == 0:\n",
    "            with torch.no_grad():\n",
    "                G.eval()\n",
    "                images_showcase = G(visualization_noise)\n",
    "                plt.figure(figsize=(8,8))\n",
    "                plt.axis(\"off\")\n",
    "                plt.title(f\"Showcase images - Epoch: {n + 1} | Iter: {it + 1}\")\n",
    "                plt.imshow(np.transpose(vutils.make_grid(images_showcase, padding=2, normalize=True, nrow=5).cpu(),(1,2,0)))\n",
    "                plt.show()\n",
    "                plots.append(np.transpose(vutils.make_grid(images_showcase, padding=2, normalize=True, nrow=5).cpu(),(1,2,0)))\n",
    "                G.train()\n",
    "\n",
    "    torch.save(G.state_dict(), f\"modelG_{n+1}.pth\")\n",
    "    torch.save(D.state_dict(), f\"modelD_{n+1}.pth\")\n",
    "    torch.save(plots, \"plots.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "Visualization of final network ouputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "noise = torch.randn(36, latent_size, 1, 1).to(device)\n",
    "\n",
    "G = G.eval().cpu()\n",
    "G.load_state_dict(torch.load(\"modelG_100.pth\"))\n",
    "G = G.cuda()\n",
    "\n",
    "image_showcase = G(noise)\n",
    "\n",
    "plt.figure(figsize=(40,40))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(image_showcase, padding=2, normalize=True, nrow=9).cpu(),(1,2,0)))\n",
    "plt.box(False)\n",
    "plt.savefig(\"final.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
